{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Lecture9_LDA_QDA_NB.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyM0YRzsKmASNK7GFw7ew0Q8",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ab-sa/Statistical-Machine-Learning3/blob/main/Lecture9_LDA_QDA_NB.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CgEv-_U2ODv8"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis, QuadraticDiscriminantAnalysis\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.model_selection import train_test_split, RepeatedKFold, cross_val_score, GridSearchCV\n",
        "import statsmodels.formula.api as smf\n",
        "import statsmodels.api as sm\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.neighbors import KernelDensity\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.base import BaseEstimator, ClassifierMixin"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "Credit = pd.read_csv('Credit.csv')\n",
        "Credit['Balance_multi'] = pd.cut(Credit.Balance, bins=[-1,300,700,2000],labels=['0','1','2'])\n",
        "Credit = Credit.drop(['ID', 'Balance', 'Limit', 'Rating'], axis=1)\n",
        "print('Dimension of the data: ' + str(Credit.shape))\n",
        "Credit.head()"
      ],
      "metadata": {
        "id": "QUFAixvZOSCk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Linear Discriminant Analysis (LDA)**: Fit an LDA with Balance_bin as response:"
      ],
      "metadata": {
        "id": "XmKv2AOROcWs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# data: dropping the credit-card related features (Limit & Rating) to make the classification problem more challenging\n",
        "X = pd.get_dummies(Credit.drop(['Balance_multi'], axis=1))\n",
        "y = Credit['Balance_multi']\n",
        "# CV\n",
        "cv = RepeatedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
        "\n",
        "# define model\n",
        "LDA_mod = LinearDiscriminantAnalysis()\n",
        "# evaluate model\n",
        "LDA_scores = cross_val_score(LDA_mod, X, y, scoring='accuracy', cv=cv, n_jobs=-1)\n",
        "# summarize result\n",
        "print('Mean Accuracy for LDA: %.3f (%.3f)' % (np.mean(LDA_scores), np.std(LDA_scores)))"
      ],
      "metadata": {
        "id": "6zDW4oZ-OfJL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Visualizing of pairwise DLs"
      ],
      "metadata": {
        "id": "rTQ1QQr7aexB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X_lda = LDA_mod.fit_transform(X, y)\n",
        "plt.xlabel('LD1')\n",
        "plt.ylabel('LD2')\n",
        "le = LabelEncoder()\n",
        "y_lab = le.fit_transform(Credit['Balance_multi'])\n",
        "plt.scatter(\n",
        "    X_lda[:,0],\n",
        "    X_lda[:,1],\n",
        "    c=y_lab,\n",
        "    cmap='rainbow',\n",
        "    alpha=0.7,\n",
        "    edgecolors='b')"
      ],
      "metadata": {
        "id": "jbXx16rhaduq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Quadratic Discriminant Analysis (QDA)**: Fit an QDA with Balance_bin as response:"
      ],
      "metadata": {
        "id": "-tj0cJ8wRdYY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# define model\n",
        "QDA_mod = QuadraticDiscriminantAnalysis()\n",
        "# evaluate model\n",
        "QDA_scores = cross_val_score(QDA_mod, X, y, scoring='accuracy', cv=cv, n_jobs=-1)\n",
        "# summarize result\n",
        "print('Mean Accuracy for QDA: %.3f (%.3f)' % (np.mean(QDA_scores), np.std(QDA_scores)))"
      ],
      "metadata": {
        "id": "A1mymaAdRfDu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Gaussian Naive Bayes (G-NB)**"
      ],
      "metadata": {
        "id": "Gzy-MM0zSfVU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Visializing density of different features:"
      ],
      "metadata": {
        "id": "Jfm_ZIYOdxic"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sns.kdeplot(data=Credit, x=\"Age\", hue=\"Balance_multi\", fill=True, common_norm=False, alpha=0.4)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "jtxcdG-8d2nn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "G-NB fit on Balance_bin with the original features (no PCA):"
      ],
      "metadata": {
        "id": "ttuYRYP44boM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# define model\n",
        "NB_mod = GaussianNB()\n",
        "# evaluate model\n",
        "NB_scores = cross_val_score(NB_mod, X, y, scoring='accuracy', cv=cv, n_jobs=-1)\n",
        "# summarize result\n",
        "print('Mean Accuracy for G-NB: %.3f (%.3f)' % (np.mean(NB_scores), np.std(NB_scores)))"
      ],
      "metadata": {
        "id": "P8Y_ncflShip"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "G-NB fit on Balance_bin with PCs:"
      ],
      "metadata": {
        "id": "-gk930lDVT6c"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x_train, x_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)\n",
        "\n",
        "# PCA\n",
        "std_scale = StandardScaler().fit(x_train)\n",
        "X_train_std = std_scale.transform(x_train)\n",
        "X_test_std = std_scale.transform(x_test)\n",
        "\n",
        "pca = PCA()\n",
        "PCs_train = pd.DataFrame(pca.fit_transform(X_train_std))\n",
        "PCs_test = pd.DataFrame(pca.transform(X_test_std))\n",
        "\n",
        "# define model\n",
        "NB_pc_mod = GaussianNB().fit(PCs_train, y_train)\n",
        "NB_pc_pred = NB_pc_mod.predict(PCs_test)\n",
        "\n",
        "# summarize result\n",
        "print(accuracy_score(y_test, NB_pc_pred))\n",
        "print(confusion_matrix(y_test, NB_pc_pred, normalize='true'))"
      ],
      "metadata": {
        "id": "48qmBIpsVXc1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Kernel density estimation naive Bayes (KDE-NB)**"
      ],
      "metadata": {
        "id": "uAeJ1UMo5Km_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "KDE-NB fit on Balance_bin with the original features (no PCA):"
      ],
      "metadata": {
        "id": "rMo8QWrb4zp8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class KDE_NB(BaseEstimator, ClassifierMixin):\n",
        "    \"\"\"Bayesian generative classification based on KDE\n",
        "    \n",
        "    Parameters\n",
        "    ----------\n",
        "    bandwidth : float\n",
        "        the kernel bandwidth within each class\n",
        "    kernel : str\n",
        "        the kernel name, passed to KernelDensity\n",
        "    \"\"\"\n",
        "    def __init__(self, bandwidth=1.0, kernel='gaussian'):\n",
        "        self.bandwidth = bandwidth\n",
        "        self.kernel = kernel\n",
        "        \n",
        "    def fit(self, X, y):\n",
        "        self.classes_ = np.sort(np.unique(y))\n",
        "        training_sets = [X[y == yi] for yi in self.classes_]\n",
        "        self.models_ = [KernelDensity(bandwidth=self.bandwidth,\n",
        "                                      kernel=self.kernel).fit(Xi)\n",
        "                        for Xi in training_sets]\n",
        "        self.logpriors_ = [np.log(Xi.shape[0] / X.shape[0])\n",
        "                           for Xi in training_sets]\n",
        "        return self\n",
        "        \n",
        "    def predict_proba(self, X):\n",
        "        logprobs = np.array([model.score_samples(X)\n",
        "                             for model in self.models_]).T\n",
        "        result = np.exp(logprobs + self.logpriors_)\n",
        "        return result / result.sum(1, keepdims=True)\n",
        "        \n",
        "    def predict(self, X):\n",
        "        return self.classes_[np.argmax(self.predict_proba(X), 1)]\n",
        "\n",
        "#class KDE_NB(BaseEstimator, ClassifierMixin):\n",
        "#    \"\"\"Bayesian generative classification based on KDE\n",
        "#    \n",
        "#    Parameters\n",
        "#    ----------\n",
        "#    bandwidth : float\n",
        "#        the kernel bandwidth within each class\n",
        "#    kernel : str\n",
        "#        the kernel name, passed to KernelDensity\n",
        "#    \"\"\"\n",
        "\n",
        "def __init__(self, bandwidth=1.0, kernel='gaussian'):\n",
        "        self.bandwidth = bandwidth\n",
        "        self.kernel = kernel\n",
        "\n",
        "def fit(self, X, y):\n",
        "        self.classes_ = np.sort(np.unique(y))\n",
        "        training_sets = [X[y == yi] for yi in self.classes_]\n",
        "        self.models_ = [KernelDensity(bandwidth=self.bandwidth,\n",
        "                                      kernel=self.kernel).fit(Xi)\n",
        "                        for Xi in training_sets]\n",
        "        self.logpriors_ = [np.log(Xi.shape[0] / X.shape[0])\n",
        "                           for Xi in training_sets]\n",
        "        return self\n",
        "\n",
        "def predict_proba(self, X):\n",
        "        logprobs = np.vstack([model.score_samples(X)\n",
        "                              for model in self.models_]).T\n",
        "        result = np.exp(logprobs + self.logpriors_)\n",
        "        return result / result.sum(1, keepdims=True)\n",
        "\n",
        "def predict(self, X):\n",
        "        return self.classes_[np.argmax(self.predict_proba(X), 1)]\n"
      ],
      "metadata": {
        "id": "SLekynhu5VRW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "bandwidths = 10 ** np.linspace(0, 2, 100)\n",
        "grid = GridSearchCV(KDE_NB(), {'bandwidth': bandwidths})\n",
        "grid.fit(X, y)\n",
        "\n",
        "print(grid.best_params_)\n",
        "print('accuracy =', grid.best_score_)\n",
        "#scores = [val.mean_validation_score for val in grid.grid_scores_]"
      ],
      "metadata": {
        "id": "OVzgLcj2kp85",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "77335430-6179-4249-cf26-a5a37b201bbe"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'bandwidth': 17.886495290574352}\n",
            "accuracy = 0.5049999999999999\n"
          ]
        }
      ]
    }
  ]
}